# Redis Demo App

Ce projet est une dÃ©monstration d'application Next.js utilisant Redis comme cache pour amÃ©liorer les performances de rÃ©cupÃ©ration de donnÃ©es depuis une API publique.

## ğŸš€ FonctionnalitÃ©s

- RÃ©cupÃ©ration de posts depuis `https://jsonplaceholder.typicode.com/posts`
- Mise en cache avec Redis (TTL = 60 secondes)
- Server-Side Rendering via App Router (`app/posts/page.tsx`)
- Logique de fallback si les donnÃ©es nâ€™existent pas dans le cache
- Comparaison des performances avant/aprÃ¨s cache

## âš™ï¸ Installation et Lancement

1. **Cloner le projet**
```bash
git clone https://github.com/chamalyamani/redis-demo-app.git
cd redis-demo-app
2. ***Installer les dÃ©pendances*
npm install
3. **Lancer Redis avec Docker**
docker run --name redis-dev -p 6379:6379 -d redis
4. **Lancer le projet**
npm run dev
5 . **Aller sur http://localhost:3000/posts**

ğŸ” Structure du projet
app/posts/page.tsx : page affichant les posts avec SSR + cache Redis
lib/redis.ts : configuration de Redis avec ioredis

ğŸ§ª RÃ©sultats de performance
ğŸŒ Sans cache : ~118 ms
âœ… Avec cache Redis : ~81 ms
MesurÃ© avec le terminal Next.js (npm run dev)

6 . **Capture des logs**
(./public/logs.png)

ğŸ“ˆ Vision de ScalabilitÃ©
Voici comment je prÃ©voirais de faire Ã©voluer cette application pour des milliers voire millions dâ€™utilisateurs :

Horizontal Scaling : DÃ©ployer lâ€™app sur plusieurs serveurs via Docker ou Vercel pour Ã©quilibrer la charge.

Redis Cluster : Utiliser un cluster Redis pour rÃ©partir le cache entre plusieurs nÅ“uds et assurer une haute disponibilitÃ©.

Microservices : SÃ©parer les responsabilitÃ©s (frontend, cache, API) pour une meilleure maintenabilitÃ©.

Load Balancer : Mettre un Ã©quilibrage de charge (NGINX ou AWS ELB) pour rÃ©partir les requÃªtes efficacement.

CDN : Utiliser un Content Delivery Network pour tout contenu statique, ce que Next.js supporte trÃ¨s bien via Vercel.

